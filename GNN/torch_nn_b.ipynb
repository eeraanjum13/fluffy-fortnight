{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 2\n",
    "lr = 0.001\n",
    "num_classes = 10\n",
    "input_size = 784\n",
    "hidden1=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.MNIST(root = './data', train = True, transform = transforms.ToTensor(), download= True)\n",
    "test = torchvision.datasets.MNIST(root = './data', train = False, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(dataset = train, batch_size = batch_size, shuffle = True)\n",
    "testset = torch.utils.data.DataLoader(dataset = test, batch_size= batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden1, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # defining the layers\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden1, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.fc1(x)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc2(output)\n",
    "\n",
    "        return F.log_softmax(output, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "net = NeuralNet(input_size, hidden1, num_classes)\n",
    "print(net)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(28, 28)\n",
    "X = X.view(1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P assing the randomized tensors through the model in a dimension which is desired. Hence we reshape the whole X tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4919, -2.3944, -2.6334, -2.2578, -2.3612, -2.2274, -2.3045, -2.2540,\n",
       "         -2.3360, -1.9243]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of NeuralNet(\n",
       "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0573, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr = lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in trainset:\n",
    "        # data is a batch of features and labels\n",
    "\n",
    "        x, y = data\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        output = net(x.view(-1, 28*28))\n",
    "\n",
    "        # now calc how wrong were we\n",
    "\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([ -4.0390, -12.4763,  -7.1594,  -1.9790,  -7.6070,  -8.0271,  -8.5430,\n",
      "         -8.4840,  -0.2721,  -2.5210], grad_fn=<UnbindBackward0>)\n",
      "tensor(8)\n",
      "1\n",
      "tensor([-1.4156e+01, -1.2875e+01, -1.1540e+01, -1.2969e+01, -1.2296e+01,\n",
      "        -9.1108e+00, -2.8106e-04, -2.5166e+01, -8.8003e+00, -2.1477e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tensor(6)\n",
      "2\n",
      "tensor([-1.5932e+01, -2.5947e+01, -1.9393e+01, -1.6551e+01, -1.6982e+01,\n",
      "        -1.4941e+01, -5.9605e-07, -2.2031e+01, -1.7209e+01, -1.8755e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tensor(6)\n",
      "3\n",
      "tensor([-2.3781e+01, -2.8083e+01, -1.4980e+01, -1.5115e+01, -3.0509e+01,\n",
      "        -2.1333e+01, -4.2369e+01, -1.0729e-06, -2.5256e+01, -1.4469e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tensor(7)\n",
      "4\n",
      "tensor([-2.3949e+01, -1.0174e+01, -2.9674e-03, -8.5721e+00, -2.8911e+01,\n",
      "        -1.4659e+01, -2.4664e+01, -1.2504e+01, -5.9030e+00, -2.0251e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tensor(2)\n",
      "5\n",
      "tensor([-1.9602e+01, -1.9932e+01, -1.2881e+01, -1.2242e+01, -2.7086e+01,\n",
      "        -1.9317e+01, -3.3474e+01, -2.3365e-05, -1.8020e+01, -1.1044e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tensor(7)\n",
      "6\n",
      "tensor([-1.4542e+01, -2.0278e+01, -1.3983e+01, -2.0093e+01, -1.2575e+01,\n",
      "        -1.3849e+01, -5.8412e-06, -1.9021e+01, -1.6697e+01, -2.1583e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tensor(6)\n",
      "7\n",
      "tensor([-1.7199e+01, -7.1965e-04, -9.8179e+00, -1.1236e+01, -1.3342e+01,\n",
      "        -1.1079e+01, -1.0516e+01, -1.0701e+01, -7.4463e+00, -1.3460e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tensor(1)\n",
      "8\n",
      "tensor([-2.2164e+01, -2.0630e+01, -1.3564e+01, -1.2842e+01, -2.9144e+01,\n",
      "        -2.4658e+01, -3.7345e+01, -4.0531e-06, -2.0778e+01, -1.5776e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tensor(7)\n",
      "9\n",
      "tensor([-15.9503, -15.1872, -15.6745, -10.1965, -15.9284,  -0.2972,  -1.3638,\n",
      "        -19.6662,  -6.5758, -12.7367], grad_fn=<UnbindBackward0>)\n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, i in enumerate(output):\n",
    "    print(idx)\n",
    "    print(i)\n",
    "    print(torch.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.978\n"
     ]
    }
   ],
   "source": [
    "correct =0 \n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        x, y = data\n",
    "\n",
    "        output = net(x.view(-1, 28*28))\n",
    "\n",
    "        for idx, out in enumerate(output):\n",
    "            if torch.argmax(out) == y[idx]:\n",
    "                correct += 1\n",
    "            \n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[9].view(28,28))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(net(x[9].view(-1, 784))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1a8d93525cc29cc11ac152c39a920e102dc18c0c52f1ba707311e2556195507"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
